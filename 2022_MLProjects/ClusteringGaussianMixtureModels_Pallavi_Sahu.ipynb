{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/GeostatsGuy/GeostatsPy/blob/master/TCG_color_logo.png?raw=true\" width=\"220\" height=\"240\" />\n",
    "\n",
    "</p>\n",
    "\n",
    "## Investigating the performance of K-means Clustering and Gaussian Mixture Models\n",
    "\n",
    "### \n",
    "\n",
    "#### Pallavi Sahu, first year PhD student \n",
    "#### Hildebrand Austin Department of Petroleum and Geosystems Engineering, UT Austin\n",
    " \n",
    "\n",
    "### Subsurface Machine Learning Course, The University of Texas at Austin\n",
    "#### Hildebrand Department of Petroleum and Geosystems Engineering, Cockrell School of Engineering\n",
    "#### Department of Geological Sciences, Jackson School of Geosciences\n",
    "\n",
    "Workflow supervision and review by:\n",
    "\n",
    "#### Instructor: Prof. Michael Pyrcz, Ph.D., P.Eng., Associate Professor, The Univeristy of Texas at Austin\n",
    "##### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)\n",
    "\n",
    "#### Course TA: Misael Morales, Graduate Student, The University of Texas at Austin\n",
    "##### [LinkedIn](https://www.linkedin.com/in/misaelmmorales/)\n",
    "\n",
    "\n",
    "\n",
    "### Executive Summary\n",
    "\n",
    "\n",
    "This notebook aim is to investigate the breakage point of k-mean clustering on data having non-similar clusters. This is an interative plot demostration of clustering methods on synthetically generated data, predominatly consist of two clusters. The relative size and spread of two clusters can be changed by slide bar of ratio of size dataset and  major and minor axis ratio of the spread of data. This workflow help to compare the performance of K-Mean clustering and Gaussian Mixture Models on data by changing the relative size and spread of dataset. It can be observed that if the relative distribution of cluster datasets  within data are non-similar then k-mean algorithm failed to cluster the data accurately. It is recommended to plot the data to see general distribution of data and advise user to cautiously use the clustering algorithms keeping the limitations of algorithms in mind.\n",
    "\n",
    "\n",
    "#### K-Mean Algorithm  And Gaussian Mixture Models for Clustering\n",
    "\n",
    "Here's a simple workflow, demonstration of assumptions of k-mean clustering. We use a:\n",
    "* K-mean Algorithm and Gaussian Mixture Models for Clustering\n",
    "* We used synthetically generated data consist of predominately two clusters.\n",
    "* We assumed equal prior probability for all clusters for a used dataset.\n",
    "\n",
    "#### k-Means Clustering\n",
    "\n",
    "The K-means clustering approach is primarly applied as an unsupervised method for classification. However, for this workflow, we have taken labelled dataset consist of two clusters. We used K-mean algorithm to find clusters in our dataset ignoring the labelled clusters. Finally we review the performance of k-mean clustering by comparing with labelled clusters.  Aim of this workflow is to check the efficiency of clustering method to cluster the data correctly when we are diverting from the algorithm assumptions.\n",
    "\n",
    "Assumptions of K-mean Clustering:\n",
    "* Spherical, Convex, isotropic clusters. There should be minimize difference within clusters.\n",
    "* Equal variance for all features \n",
    "* Similar size/ frequency data\n",
    "* Equal prior probability for all clusters\n",
    " \n",
    "Advantanges\n",
    "* Relatively simple to implement.\n",
    "* Scales to large data sets.\n",
    "* Guarantees convergence.\n",
    "* Can warm-start the positions of centroids.\n",
    "* Easily adapts to new examples.\n",
    "\n",
    "Diasadvantages\n",
    "* k-means has trouble clustering data where clusters are of varying sizes and density.\n",
    "* Centroids can be dragged by outliers, or outliers might get their own cluster instead of being ignored. \n",
    "\n",
    "\n",
    "We’ll use some of the available functions in the Scikit-learn library to process the randomly generated data.\n",
    "                                 Kmean = KMeans(n_clusters=2)\n",
    "\n",
    "#### Gaussian Mixture Models\n",
    "\n",
    "A Gaussian Mixture is a function that is comprised of several Gaussians, each identified by k ∈ {1,…, K}, where K is the number of clusters of our dataset.In one dimension the probability density function of a Gaussian Distribution is given by: \n",
    "\n",
    "\\begin{equation}\n",
    "G( X | µ) = \\frac{\\exp^\\frac{-(x-\\mu )^2}{\\sigma^2}}{\\sigma^2   √2π}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mu$     and $\\sigma^2$     are respectively mean and variance of the distribution.\n",
    "\n",
    "\n",
    "Each Gaussian k in the mixture is comprised of the following parameters:\n",
    "* A mean μ that defines its centre.\n",
    "* A covariance Σ that defines its width. This would be equivalent to the dimensions of an ellipsoid in a multivariate scenario.\n",
    "* A mixing probability π that defines how big or small the Gaussian function will be.\n",
    "* It works so well on non-linear datasets.\n",
    "\n",
    "\n",
    "Advantages:\n",
    "\n",
    "* Does not assume clusters to be of any geometry. Works well with non-linear geometric distributions as well.\n",
    "* Does not bias the cluster sizes to have specific structures as does by K-Means (Circular).\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "* Uses all the components it has access to, so initialization of clusters will be difficult when dimensionality of data is high.\n",
    "* Difficult to interpret.\n",
    "\n",
    "\n",
    "sklearn.mixture package is used to learn Gaussian Mixture Models (diagonal, spherical, tied and full covariance matrices supported), sample them, and estimate them from data. \n",
    "\n",
    "                                  gmm = GMM(n_components=2).fit(X)\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "##### Generating Synthetic Data\n",
    "We have used numpy.random.normal from numpy library to draw random samples from a normal (Gaussian) distribution. We have synthetically generated data taken from two normal (Gaussian) distribution.\n",
    "\n",
    "                                  random.normal(loc=0.0, scale=1.0, size=500)\n",
    "\n",
    "Parameters:\n",
    "* location or array_like of floats: Mean (“centre”) of the distribution.\n",
    "* scale or array_like of floats: Standard deviation (spread or “width”) of the distribution. Must be non-negative.\n",
    "* sizeint or tuple of ints, size of dataset\n",
    "\n",
    "For this workflow, \n",
    "* We have taken two centre of distribution for two clusters((5,5) & (10,1)). This can be changed as per the user.\n",
    "* The spread of one cluster distribution is fixed to (1,1). And the spread of another cluster can be changed by slide bar w.r.t to first cluster.\n",
    "* The size one cluster is fixed to 500 and the size of another cluster can be changed by slide bar w.r.t to first cluster.\n",
    "\n",
    "References:\n",
    "\n",
    "* https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1\n",
    "* https://scikit-learn.org/stable/modules/mixture.html\n",
    "* https://github.com/GeostatsGuy\n",
    "* https://medium.com/@yara.ahmed.amin/gaussian-mixture-model-4c71342b67d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Required Libraries\n",
    "\n",
    "The following code loads the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive                        # widgets and interactivity\n",
    "from ipywidgets import widgets                            # widgets and interactivity\n",
    "import matplotlib; import matplotlib.pyplot as plt        # plotting\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\n",
    "plt.rc('axes', axisbelow=True)                  # set axes and grids in the background for all plots\n",
    "import numpy as np                                        # working with arrays\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import mixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Make Our Interactive Plot \n",
    "\n",
    "For this demonstration we will: \n",
    "\n",
    "* declare a set of 2 widgets in a HBox (horizontal box of widgets). \n",
    "\n",
    "\n",
    "* define a function 'f' that will read the output from these widgets and make a plot\n",
    "\n",
    "You may have some flicker and lag.  I have not tried to optimize performance for this demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 slider bars for the model input\n",
    "# 1- The size of one of the cluster is fixed. The size of another cluster can be changed w.r.t the size of first cluster by changing the ratio.\n",
    "# 2- The spread of one cluster is fixed. The spread of another cluster can be changed w.r.t the spread of first cluster by changing the ratio.\n",
    "a = widgets.FloatSlider(min=1, max = 100.0, value = 0.5, description = 'Size Ratio',continuous_update=False)\n",
    "b = widgets.FloatSlider(min=0.1, max = 10.0, value = 0.5, step = 0.01, description = ' Axis Ratio',continuous_update=False)\n",
    "\n",
    "ui = widgets.HBox([a,b],)\n",
    "\n",
    "# function to make the plot  \n",
    "def f(a, b):    \n",
    "     \n",
    "    n=500  # Selected size of first cluster\n",
    "    m=int(500*a) # Size of second cluster w.r.t to first chosen by Ratio slide bar\n",
    "    location_cluster_1=(1,1) # Selected location of first cluster\n",
    "    location_cluster_2=(1,b) # Location of second cluster w.r.t to first chosen by  Axis slide bar\n",
    "    \n",
    "    # Generating the Synthetic Datasets\n",
    "    x1 = np.random.normal((5,5), location_cluster_1, (n,2))\n",
    "    x2 = np.random.normal((10,1), location_cluster_2, (m,2))\n",
    "\n",
    "    n=np.shape(x1)[0]\n",
    "    # Putting labels to the selected dataset\n",
    "    X1 = np.append(x1,np.ones([len(x1),1]),1)\n",
    "    X2 = np.append(x2,np.zeros([len(x2),1]),1)\n",
    "    X=np.concatenate((X1,X2),axis=0)\n",
    "    df=pd.DataFrame(X)\n",
    "    shuffled = shuffle(df)\n",
    "    df=shuffled.iloc[:, [0,1]]\n",
    "    \n",
    "    # Using K-mean algorithm to find Clusters\n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    kmeans.fit(df)\n",
    "    k_mean_labels=kmeans.labels_\n",
    "    \n",
    "    # Using Gaussian Mixture Models algorithm to find Clusters\n",
    "    gmm = GMM(n_components=2)\n",
    "    Y=gmm.fit(df)\n",
    "    gmm_labels = gmm.predict(df)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Ploting the Plots\n",
    "    plt.subplot(131)\n",
    "    plt.scatter(x1[:,0], x1[:,1], label='x1')\n",
    "    plt.scatter(x2[:,0], x2[:,1], label='x2')\n",
    "    plt.title('Original Labelled Data')\n",
    "    plt.xlabel('Property 1') \n",
    "    plt.ylabel('Property 2')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.scatter(df[0], df[1], c=kmeans.labels_)\n",
    "    plt.title('Clusters by k_mean Clustering')\n",
    "    plt.xlabel('Property 1') \n",
    "    plt.ylabel('Property 2')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.scatter(df[0], df[1], c=gmm_labels)\n",
    "    plt.title('Clusters by Gaussian Mixture Models')\n",
    "    plt.xlabel('Property 1') \n",
    "    plt.ylabel('Property 2')\n",
    "\n",
    "    \n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=0.8, wspace=0.2, hspace=0.1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interactive_plot = widgets.interactive_output(f, {'a': a, 'b': b})\n",
    "interactive_plot.clear_output(wait = True)                # reduce flickering by delaying plot updating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "This is an interactive plot. The size and spread of dataset can be changed by sliding the slide bar. The three plots shows:\n",
    "1) Shows plot of original labelled data.\n",
    "2) Shows plot of clusters clustered by the K-Mean algorithm.\n",
    "3) Shows plot of clusters clustered by Gaussian Mixture Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9de21d45bf4b6883ca8008d0f1f615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=1.0, continuous_update=False, description='Size Ratio', min=1.0), FloatSlider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396c35a2d2a74596bb353597bf8679b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ui, interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We can change the size and spread of the dataset by changing the sliding bar. When we voliate the assumption of k mean algorithm that the dataset should be of similar size/ frequency data, by increasng the ratio of relative size of dataset of clusters and relative spread, the accuracy of k-mean algorithm to cluster the data decreases. This illustrates the limitation of k mean cluster algorithm to cluster the datasets having unsimilar datasets.  \n",
    "\n",
    "However, Gaussian Mixture Models that does not assume clusters to be of any geometry, works well with unsimilar datasets having different sizes and non-linear geometric distributions as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "I hope this was helpful,\n",
    "\n",
    "*Pallavi Sahu*\n",
    "\n",
    "\n",
    "___________________\n",
    "\n",
    "#### Work Supervised by:\n",
    "\n",
    "### Michael Pyrcz, Associate Professor, University of Texas at Austin \n",
    "*Novel Data Analytics, Geostatistics and Machine Learning Subsurface Solutions*\n",
    "\n",
    "With over 17 years of experience in subsurface consulting, research and development, Michael has returned to academia driven by his passion for teaching and enthusiasm for enhancing engineers' and geoscientists' impact in subsurface resource development. \n",
    "\n",
    "For more about Michael check out these links:\n",
    "\n",
    "#### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)\n",
    "\n",
    "#### Want to Work Together?\n",
    "\n",
    "I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.\n",
    "\n",
    "* Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I'd be happy to drop by and work with you! \n",
    "\n",
    "* Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PIs including Profs. Foster, Torres-Verdin and van Oort)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!\n",
    "\n",
    "* I can be reached at mpyrcz@austin.utexas.edu.\n",
    "\n",
    "I'm always happy to discuss,\n",
    "\n",
    "*Michael*\n",
    "\n",
    "Michael Pyrcz, Ph.D., P.Eng. Associate Professor The Hildebrand Department of Petroleum and Geosystems Engineering, Bureau of Economic Geology, The Jackson School of Geosciences, The University of Texas at Austin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
