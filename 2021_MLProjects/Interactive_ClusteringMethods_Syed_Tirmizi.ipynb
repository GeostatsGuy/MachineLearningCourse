{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/GeostatsGuy/GeostatsPy/blob/master/TCG_color_logo.png?raw=true\" width=\"220\" height=\"240\" />\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Interactive Workflow for Understanding Different Clustering Methods (Educational Tool)\n",
    "\n",
    "#### Syed Talha Tirmizi (UT EID: st35345)\n",
    "#### Hildebrand Department of Petroleum and Geosystems Engineering, Cockrell School of Engineering\n",
    "\n",
    "### Subsurface Machine Learning Course, The University of Texas at Austin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_____________________\n",
    "\n",
    "Workflow supervision and review by:\n",
    "\n",
    "#### Instructor: Prof. Michael Pyrcz, Ph.D., P.Eng., Associate Professor, The Univeristy of Texas at Austin\n",
    "##### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)\n",
    "\n",
    "#### Course TA: Ademide Mabadeje, Graduate Student, The University of Texas at Austin\n",
    "##### [LinkedIn](https://www.linkedin.com/in/ademidemabadeje/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executive Summary\n",
    "\n",
    "* What is the gap, problem, opportunity, scientific question?\n",
    "\n",
    "There are many clustering methods to choose from, including the popular sklearn library has a variety of around thirteen different clustering methods. The answer to choosing the best clustering method depends on the data, similar to most of the questions answered based on the data in the field of data science and machine learning. This workflow is an educational tool for new learners to understand the difference between various clustering methods, given with the flexibility to make changes in the data. This gives them a two-way learning opportunity to understand the clustering methods based on the differences between them and with different datasets. \n",
    "\n",
    "* What was done to address the above?\n",
    "\n",
    "An interactive workflow is developed keeping in view the goal of educational tool. The goal here is to understand the clustering methods. So, three different clustering methods have been incorporated which are mentioned below:\n",
    "\n",
    "(a) DBSCAN (Density Based Spatial Clustering of Applications with Noise) which is a density based clustering method.\n",
    "\n",
    "(b) K-means clustering which is a centroid based clustering method.\n",
    "\n",
    "(c) Hierarchical Agglomerative Clustering which is connectivity based clustering method. Here, it is worth mentioning that ward linkage method is used which analyzes the variance of clusters instead of measuring the distance. It is most suitable for quantitative variables. \n",
    "\n",
    "* What was learned?\n",
    "\n",
    "The choice of clustering methods could not be understood without the understanding of the considered dataset. The number of datapoints can change our preferences among the clustering methods. Also, the clusters are made based on the assumptions made by the clustering methods as k-means clustering method assumes the clusters of spherical shape, which is not desirable if our dataset has datapoints forming moon shape and blob shapes near to each other. DBSCAN performs better in clustering but as the moon shape clusters spread, it tends to become unfavorable. \n",
    "\n",
    "* What are your recommendations?\n",
    "\n",
    "Educating different types of clustering methods with the same dataset would not give a comprehensive understanding to the students, therefore, different datasets should be used with the clustering methods, so that the students can understand it in-depth, helpling to decide which clustering method to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will import several Python packages, which are basically a collection of modules. The purpose of each package has been addressed in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                        # ndarrys for gridded data\n",
    "import pandas as pd                       # DataFrames for tabular data\n",
    "import matplotlib.pyplot as plt           # for plotting\n",
    "from sklearn.neighbors import NearestNeighbors # nearest neighbours function to calculate eps hyperparameter\n",
    "from sklearn.preprocessing import MinMaxScaler # min/max normalization\n",
    "from sklearn.cluster import KMeans        # k-means clustering\n",
    "from sklearn.cluster import DBSCAN        # DBSCAN clustering\n",
    "from sklearn.cluster import AgglomerativeClustering #Hierarchical Agglomerative Clustering\n",
    "import scipy.cluster.hierarchy as sch     # for dendrogram\n",
    "from sklearn.datasets import make_moons   # import moons dataset\n",
    "from sklearn.datasets import make_blobs   # import blobs dataset\n",
    "import warnings # import warnings library\n",
    "# to enable the inline plotting\n",
    "%matplotlib inline  \n",
    "warnings.filterwarnings(\"ignore\") #to avoid unnecessary warning messages\n",
    "import time #import library for calculating execution time\n",
    "from matplotlib import pyplot as plt #for graph visualization\n",
    "from sklearn import cluster, datasets, mixture # for clustering purpose\n",
    "from ipywidgets import Button, Layout # for interactive workflow development\n",
    "import ipywidgets as widgets # for interactive workflow development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most brief sense, functions are a set of codes for a particular task and can be called whenever required. Three functions have been defined below.\n",
    "* The first function is for creating a dataset based on user's preference. This gives the flexibility to the user to modify the data and understand the clustering methods more comprehensively. \n",
    "* The second function is used for assiging different clusters for the purpose of plotting and labeling them for the plot's legend.\n",
    "* After the clustering method has been executed, it is important to display its results in the form of a plot. So, the third function is used to create the plot. This function has a while loop which calls the second function (cluster_grouping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def keyword is used to define the function \n",
    "# def function_name(arguments):\n",
    "\n",
    "def make_data(Sld_blob_noOfdata, Sld_moon_noOfdata): \n",
    "    # blob means a drop of a thick liquid or viscous substance. Therefore, it creates circular shape datapoints as seen in the plots.\n",
    "    blob = make_blobs(Sld_blob_noOfdata, centers = 2, center_box =(-1.7,1.7), cluster_std=0.1,random_state=19) # function from sklearn, https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html\n",
    "    # moon shape pattern datapoints are create below\n",
    "    moons = make_moons(Sld_moon_noOfdata, noise=0.08, random_state=19) \n",
    "    # below a global variable is defined which could be used across different functions and code.\n",
    "    # X is the user generated dataset which will be used for the clustering methods\n",
    "    global X;\n",
    "    # vstack() function is used to stack arrays in sequence vertically \n",
    "    X = np.vstack((moons[0], blob[0]));\n",
    "    # above function has been learnt from Saul, N.: https://github.com/scikit-learn-contrib/hdbscan/blob/master/docs/how_hdbscan_works.rst\n",
    "    \n",
    "    \n",
    "def cluster_grouping(index, y_c):                          #for grouping the clusters in the graph\n",
    "    # used to create an array of different colors to be used for different clusters within the data\n",
    "    #color = ['red', 'green', 'blue', 'orange', 'cyan', 'gray', 'brown', 'olive', 'purple', ]\n",
    "    # cluster_label will be displayed in the legend of the plot, to identify which cluster is of which color  \n",
    "    cluster_label = 'Cluster ' + str(index+1)\n",
    "    #this is used to generate a scatter plot. \n",
    "    #plt.scatter(x values, y values, s(marker size), c for color of each cluster, label)\n",
    "    plt.scatter(X[y_c == index, 0], X[y_c == index, 1], \\\n",
    "                s = 100, c = [np.random.rand(3,)], label = cluster_label);\n",
    "    \n",
    "\n",
    "def visualize_graphs(n_clusters, y_c):      # for creating the cluster graph\n",
    "    plt.figure(figsize=((12,8)));           # creates figure object\n",
    "    index = 0;                              # index is set to zero, index will be used for while loop till the total number of clusters\n",
    "    while index < n_clusters[0]:\n",
    "        cluster_grouping(index, y_c)        # function is called with two arguments\n",
    "        index = index + 1                   # increment in index value by 1\n",
    "    plt.title(dropdown.value)               # plot title is set to the name of the clustering method chosen in dropdown box\n",
    "    plt.xlabel('X')                         # label for x axis\n",
    "    plt.ylabel('Y')                         # label for y axis\n",
    "    plt.text(1, -1, r\"Number of predicted clusters: \" + str(n_clusters)) # text will be displayed inside the plot area to indicate the number of predicted clusters\n",
    "    plt.text(0.99,0.01,(\"%.2fs\" % (t1 - t0)).lstrip(\"0\"), transform=plt.gca().transAxes, size=15, horizontalalignment=\"right\") # to display the execution time of the clustering method, Orbifold consulting (https://orbifold.net/default/outlier-detection/)\n",
    "    plt.legend()                            # displays legend in the plot\n",
    "    plt.show()                              # displays the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the widgets and layout of the Interactive Workflow using Ipywidget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ipywidgets: Ipywidgets, python library, are also called as python widgets or simply widgets. They are interactive HTML widgets for Jupyter Notebook. \n",
    "\n",
    "Interactive widgets are a great way to introduce an immersive learning experience which is very important for efficient education tool. This allows the user to gain control over the data and visualize it with the help of plots. The user can also understand how changing the data can impact the different types of clustering methods or how the clustering methods differ in the way they form clusters.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have used different types of widgets which includes:\n",
    "* slider\n",
    "* dropdown\n",
    "* buttons\n",
    "\n",
    "The following code block has codes learnt from different videos by Qiusheng Wu, Playlist: Geographic Software Design from [Youtube: Geographic Software Design](https://www.youtube.com/playlist?list=PLAxJ4-o7ZoPeUqGpMhvJoVk5G-TrvMAd-) and Jupyter Widgets, [Widget List](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html).\n",
    "\n",
    "The below code block also has the elbow method and dendrogram method to find the number of cluster for the case of k-means clustering and hierarchical agglomerative clustering method, respectively. \n",
    "\n",
    "Elbow method is used to find the optimal number of clusters by fitting the model over a large number of K values. \n",
    "Dendrogram method is used for Hierarchical Agglomerative Clustering (HAC) to find the optimal number of clusters based on the tree-diagram representing hierarchical relationships between different sets of the data. In it, the distance between clusters is shown by the heights of the blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "widget_width = \"800px\" #widget width\n",
    "padding = \"0px 0px 0px 4px\" #upper, right, bottom, left\n",
    "layout = widgets.Layout(width='auto', height='30px') #layout used for buttons\n",
    "\n",
    "blobs_slider = widgets.IntSlider( # slider used to define the number of data points in blob shapes\n",
    "    min = 0,                      # minimum value of the slider\n",
    "    max = 400,                    # maximum value of the slider\n",
    "    description = \"Number of samples in blobs shape :\",  # description used to display for the slider\n",
    "    readout = True,               # shows the present value of the slider besides it\n",
    "    continuous_update = True,     # restricts executions to mouse release events\n",
    "    layout = widgets.Layout(width=\"400px\", padding=padding), # sets the layout and padding value of the slider\n",
    "    style={\"description_width\": \"initial\"},   # full description text is shown\n",
    ")\n",
    "\n",
    "moons_slider = widgets.IntSlider( # slider used to define the number of data points in moon shapes\n",
    "    min = 0,                      # minimum value of the slider\n",
    "    max = 400,                    # maximum value of the slider\n",
    "    description = \"Number of samples in moons shape :\", # description used to display for the slider\n",
    "    readout = True,               # shows the present value of the slider besides it\n",
    "    continuous_update = True,     # restricts executions to mouse release events\n",
    "    layout = widgets.Layout(width=\"400px\", padding=padding), # sets the layout and padding value of the slider\n",
    "    style={\"description_width\": \"initial\"},   # full description text is shown\n",
    "    \n",
    ")\n",
    "\n",
    "kmeans_int_slider = widgets.IntSlider(  # slider used to define the number of clusters to used\n",
    "    min = 0,                            # minimum value of the slider\n",
    "    max = 20,                           # maximum value of the slider\n",
    "    description = \"Number of clusters in K-means/HAC :\",   #description used to display for the slider\n",
    "    readout = True,                     # shows the present value of the slider besides it\n",
    "    continuous_update = True,           # restricts executions to mouse release events\n",
    "    layout = widgets.Layout(width=\"400px\", padding=padding), # sets the layout and padding value of the slider\n",
    "    style={\"description_width\": \"initial\"}, # full description text is shown\n",
    "    \n",
    ")\n",
    "\n",
    "dbscan_float_slider = widgets.FloatSlider(   # slider used to define the eps value to be used in DBSCAN\n",
    "    min = 0,                            # minimum value of the slider\n",
    "    max = 1,                            # maximum value of the slider\n",
    "    description = \"eps (DBSCAN only) :\",  # description used to display for the slider\n",
    "    readout = True,                     # shows the present value of the slider besides it\n",
    "    continuous_update = True,           # restricts executions to mouse release events\n",
    "    layout = widgets.Layout(width=\"400px\", padding=padding), # sets the layout and padding value of the slider\n",
    "    style={\"description_width\": \"initial\"}, # full description text is shown\n",
    "    \n",
    ")\n",
    "\n",
    "dropdown = widgets.Dropdown(             #used to define the dropdown menu\n",
    "    options=[\"DBSCAN\", \"Kmeans\", \"Hierarchical Agglomerative Clustering\"],  # set the value for the dropdown\n",
    "    value=None,                # value to be shown in the dropdown initially\n",
    "    description=\"Clustering Method: \",   # description used to display for the dropdown\n",
    "    style={\"description_width\": \"initial\"}, # full description text is shown\n",
    "    layout=widgets.Layout(width=\"400px\")  # layout in which the width of the dropdown is defined\n",
    ")\n",
    "\n",
    "\n",
    "# Buttons are learnt from https://medium.com/@jdchipox/how-to-interact-with-jupyter-33a98686f24e\n",
    "\n",
    "#initiating the button with its layout values\n",
    "submit_data_btn = widgets.Button(description='Submit Data', button_style = \"info\", layout=layout, display='flex', flex_flow='column', align_items='stretch')\n",
    "\n",
    "# function to be executed when the button is pressed\n",
    "def submit_data_btn_clicked(_):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        Sld_blob_noOfdata = blobs_slider.value    # extract the value of the blob slider\n",
    "        Sld_moon_noOfdata = moons_slider.value    # extract the value of the moon slider\n",
    "        make_data(Sld_blob_noOfdata, Sld_moon_noOfdata);  #execute the function to generate the data\n",
    "        print(\"Data has been submitted successfully\")   # display message to confirm the successful execution\n",
    "\n",
    "submit_data_btn.on_click(submit_data_btn_clicked)  # this links the button with its respective function\n",
    "\n",
    "#initiating the button with its layout values\n",
    "run_btn = widgets.Button(description='Run', button_style = \"info\", layout=layout, display='flex', flex_flow='column', align_items='stretch')\n",
    "\n",
    "# function to be executed when the button is pressed\n",
    "def run_btn_clicked(_):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        plt.clf()     # this clears the graphs if displayed previously\n",
    "        global t1, t0 # set the global variable for the time of execution\n",
    "        t0 = time.time() # store the initial time of execution\n",
    "        n_clusters_submitted = kmeans_int_slider.value   # submits the number of clusters to be used in clustering methods\n",
    "        #below clustering methods from https://cprosenjit.medium.com/8-clustering-methods-from-scikit-learn-we-should-know-e2ff7ee9ca18 \n",
    "        if dropdown.value == \"DBSCAN\":    \n",
    "            dbscan = DBSCAN(dbscan_float_slider.value, metric='euclidean') #runs the DBSCAN function excerpt from scikit-learn library\n",
    "            y_c = dbscan.fit_predict(X)  # fit the data to DBSCAN   \n",
    "            labels = dbscan.labels_ # load the generated cluster indices into labels \n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0) # calculate the number of clusters\n",
    "            t1 = time.time() # store the final time of execution\n",
    "            visualize_graphs([n_clusters], y_c) # executes the function to generate the figure to display the clusters\n",
    "                \n",
    "        elif dropdown.value == \"Kmeans\":    \n",
    "            # submits the number of clusters to be used in clustering methods\n",
    "            kmeans = KMeans(n_clusters_submitted, \\\n",
    "            # selects initial cluster centers for k-mean clustering\n",
    "            init = 'k-means++', \\\n",
    "            random_state = 42) # choose n_clusters at random from data for the starting centroids\n",
    "            y_c = kmeans.fit_predict(X)  # fit the data to K-means\n",
    "            t1 = time.time() # store the final time of execution\n",
    "            visualize_graphs([n_clusters_submitted], y_c) # executes the function to generate the figure to display the clusters\n",
    "                \n",
    "        elif dropdown.value == \"Hierarchical Agglomerative Clustering\": \n",
    "            #number of clusters to be used \n",
    "            hc = AgglomerativeClustering(n_clusters_submitted, \\\n",
    "            # to compute the linkage\n",
    "                             affinity = 'euclidean', \\\n",
    "             # in our case affinity = euclidean, therefore only ward linkage is acceptable. Ward linkage analyzes the variance of clusters instead of measuring the distance. It is most suitable for quantitative variables.\n",
    "                             linkage = 'ward')\n",
    "            y_c = hc.fit_predict(X)  # fits the data to HAC\n",
    "            t1 = time.time() # store the final time of execution\n",
    "            visualize_graphs([n_clusters_submitted], y_c) # executes the function to generate the figure to display the clusters\n",
    "\n",
    "            \n",
    "run_btn.on_click(run_btn_clicked) # this links the button with its respective function\n",
    "\n",
    "#initiating the button with its layout values\n",
    "submit_nclusters_btn = widgets.Button(description='Submit No. of Clusters for K-means/HAC', button_style = \"info\", layout=layout, display='flex', flex_flow='column', align_items='stretch')\n",
    "\n",
    "\n",
    "# function to be executed when the button is pressed\n",
    "def submit_nclusters_btn_clicked(_):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        n_clusters = kmeans_int_slider.value\n",
    "        print(kmeans_int_slider.value)\n",
    "\n",
    "submit_nclusters_btn.on_click(submit_nclusters_btn_clicked) # this links the button with its respective function\n",
    "\n",
    "#initiating the button with its layout values\n",
    "find_nclusters_btn = widgets.Button(description='Find No. of Clusters', button_style = \"info\", layout=layout, display='flex', flex_flow='column', align_items='stretch')\n",
    "\n",
    "# function to be executed when the button is pressed\n",
    "def find_nclusters_btn_clicked(_):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        #elbow and dendrogram method from https://cprosenjit.medium.com/8-clustering-methods-from-scikit-learn-we-should-know-e2ff7ee9ca18 \n",
    "        if dropdown.value == \"Kmeans\":\n",
    "            sum_sqrd = [] # define the sum of squared distance\n",
    "            for i in range(1, 11):  #starts the for loop to be run 11 times\n",
    "                # submits the number of clusters to be used in clustering methods\n",
    "                kmeans = KMeans(n_clusters = i, \\\n",
    "                                # initializing the centroid.\n",
    "                                init = 'k-means++', \\\n",
    "                                # choose n_clusters at random from data for the starting centroids\n",
    "                                random_state = 42)\n",
    "                kmeans.fit(X) # fit the data to K-means\n",
    "                sum_sqrd.append(kmeans.inertia_) #Sum of squared distances of samples to their closest cluster center\n",
    "            plt.plot(range(1, 11), sum_sqrd) \n",
    "            plt.title('K-Means - the Elbow method')\n",
    "            plt.xlabel('Number of clusters')\n",
    "            plt.ylabel('Sum of squared distances')\n",
    "            plt.show()\n",
    "        elif dropdown.value == \"Hierarchical Agglomerative Clustering\": \n",
    "            print(\"Please wait\") # it takes long for the dendrogram figure to display\n",
    "            plt.figure(figsize=(35,12))\n",
    "            dendrogram = sch.dendrogram(\\\n",
    "                                        #Execute hierarchical agglomerative clustering.\n",
    "                                        sch.linkage(X, \\\n",
    "                                                    # distance metric\n",
    "                                                    metric='euclidean', \\\n",
    "                                                    # variance minimization algorithm\n",
    "                                                    method = 'ward'))\n",
    "            plt.title('Dendrogram')               \n",
    "            plt.xticks(fontsize=14, rotation=90)\n",
    "            plt.show()\n",
    "        else:\n",
    "            #in case the K-means or HAC is not selected in the dropdown menu, following text will be displayed.\n",
    "            print(\"Please select the appropriate clustering method in the dropdown menu above\") \n",
    "\n",
    "# initiating the button with its layout values\n",
    "find_nclusters_btn.on_click(find_nclusters_btn_clicked) # this links the button with its respective function\n",
    "\n",
    "#initiating the button with its layout values\n",
    "submit_eps_btn = widgets.Button(description='Submit eps (DBSCAN)', button_style = \"info\", layout=layout, display='flex', flex_flow='column', align_items='stretch')\n",
    "\n",
    "# function to be executed when the button is pressed\n",
    "def submit_eps_btn_clicked(_):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        eps = dbscan_float_slider.value     #extract the value for the local radius for expanding clusters\n",
    "        print(dbscan_float_slider.value)   # prints the extracted value\n",
    "\n",
    "# initiating the button with its layout values        \n",
    "submit_eps_btn.on_click(submit_eps_btn_clicked) # this links the button with its respective function\n",
    "        \n",
    "output = widgets.Output() # to display output\n",
    "\n",
    "def dropdown_change(change):\n",
    "    if change['new']: #if the dropdown menu changes to a new value\n",
    "        with output:\n",
    "            output.clear_output() \n",
    "            print(change['new'])  # displays the selected dropdown value\n",
    "            \n",
    "dropdown.observe(dropdown_change, \"value\") #links the dropdown with its respective function\n",
    "\n",
    "#display the widgets in the following manner with the help of VBox and HBox\n",
    "# VBox: to layout all their children in one vertical row \n",
    "# HBox: to layout all their children in one horizontal row \n",
    "toolbar_widget = widgets.VBox()\n",
    "toolbar_widget.children = [\n",
    "    widgets.HBox([blobs_slider, moons_slider]),\n",
    "    dropdown,\n",
    "    widgets.HBox([kmeans_int_slider]),\n",
    "    widgets.HBox([dbscan_float_slider]),\n",
    "    widgets.HBox([submit_data_btn, find_nclusters_btn, submit_nclusters_btn]),\n",
    "    widgets.HBox([submit_eps_btn, run_btn]),\n",
    "    output,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPyWidgets, a python library, used to create HTML interactive widgets for the Jupyter notebook. These widgets are used to make the workflow interactive for the user, using various sliders, buttons and dropdown menu. The widgets remain active and updates the values according to the user interaction. \n",
    "The workflow is designed in a way to simplify the interactivity as much as possible while also focusing on its main goal. The following instructions are mentioned as a guideline for the user:\n",
    "\n",
    "1. The present workflow provides the flexibility to the user to create its own data in specific shapes. User can increase/decrease the number of datapoints. Therefore, use the first two sliders to change the number of data samples in the shape of moon and blob respectively. Then press the \"Submit Data\" button to store the generate and store the data.\n",
    "\n",
    "2. Choose the desired clustering method from the drop down menu.\n",
    "\n",
    "3. If you have chosen \"DBSCAN\" as your desired clustering method, you will choose the epsilon parameter's value from the indicated slider and press the \"Submit eps (DBSCAN)\" button. You can now skip to point no. 6.\n",
    "\n",
    "4. If you have chosen the \"K-means\" as your desired clustering method, you need to press the \"Find No. of Clusters\" button first to pick a value using the elbow method. A graph will be shown for your convenience.\n",
    "\n",
    "5. If you have chosen the \"Hierarchical Agglomerative Clustering\" as your desired clustering method in the dropdown menu, you need to press the \"Find No. of Clusters\" button first to pick a value using Dendrogram graph, which will take a few moments to be displayed (depending on your computational power)\". \n",
    "\n",
    "6. Now press the run button, to execute the desired clustering method and a graph will be shown below, highlighting the different clusters in the data and the number of predicted clusters. The time for execution of the particular clustering method is also displayed at the bottom-right corner of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130a2a63c4aa4eeea66988b1e2390143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, description='Number of samples in blobs shape :', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toolbar_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The user has the flexibility to define its own dataset with different shapes. The interactive workflow provides the opportunity to understand the different clustering methods, with well illustrated plot. The workflow also gives an option to determine the optimal number of clusters for K-means and Hierarchical Agglomerative Clustering methods with the help of elbow method and dendrogram method, respectively. Changing the eps value for the case of DBSCAN, the user can understand its impact on the number of clusters in the data. The plot also shows the execution time for each clustering method in the bottom-right corner. \n",
    "\n",
    "Although it’s a relatively faster method, K-means clustering has the limitation that it can’t deal with the non-convex cluster shapes, hence, it is not always an ideal clustering method. On the other hand, the DBSCAN can form clusters of arbitrary shapes. For example, if you take k-means clustering method and DBSCAN method over the same dataset, it will show different clustering patterns. The other key point to notice here is that the Hierarchical Agglomerative Clustering and K-means clustering requires to pre-define the number of clusters however, DBSCAN forms new clusters based on the data. If the value of epsilon is taken to be very high, it will not form appropriate clusters, try taking eps = 0.6. Therefore, DBSCAN needs careful selection of its parameters to form clustering. It doesn’t work well over clusters with different densities. \n",
    "\n",
    "\n",
    "I hope this was helpful,\n",
    "\n",
    "Syed Talha Tirmizi\n",
    "\n",
    "___________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
